{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0257d94",
   "metadata": {},
   "source": [
    "## TODO \n",
    "First i want to try COT , then i will try to use COT + gem 2.5 flash \n",
    "after that if that does not increase the accuracy i wil try preprocessing the image first.\n",
    "if that does not work i will try and and have it in a graph that would have VLM first then answering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27511e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "import os, getpass\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL.Image\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic_ai import Agent, RunContext,ImageUrl,BinaryContent\n",
    "load_dotenv()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef232edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent('gemini-2.5-flash-lite-preview-09-2025')\n",
    "\n",
    "@agent.system_prompt\n",
    "def context():\n",
    "\n",
    "    return \"\"\"\n",
    "    \n",
    "    You are an expert mathematician. Analyze the provided image and question to arrive at a solution. Follow these steps precisely in your response:\n",
    "    Step 1: Diagram Deconstruction.\n",
    "    Identify the type of mathematical diagram (e.g., 'Linear inequality graph,' 'Venn diagram,' 'Histogram').\n",
    "    Extract all key features directly from the diagram. For a graph, list the equations of the lines, intercepts, and labeled points. For a chart, extract the data points. For a network, list the nodes and edges with their weights.\n",
    "    Step 2: Question Interpretation.\n",
    "    State the explicit goal of the question. What specific value or statement needs to be produced?\n",
    "    Step 3: Mathematical Formulation.\n",
    "    Based on the deconstructed diagram from Step 1 and the question from Step 2, formulate the necessary mathematical equations, inequalities, or logical statements.\n",
    "    Step 4: Step-by-Step Calculation.\n",
    "    Solve the formulation from Step 3. Show every step of your calculation.\n",
    "    Step 5: Final Answer.\n",
    "    State the final answer clearly, ensuring it directly addresses the question.\n",
    "    \"\"\"\n",
    "with open(r'C:\\Users\\Adonis\\OneDrive\\Desktop\\DataScience\\evaluation\\QAs\\Soalan maths\\form 4\\Chapter 10_Q2.png','rb') as f:\n",
    "        image_data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = await agent.run([\n",
    "    'Solve the following question i want you to first analayze the questions then start solving make sure your answer is complete, dont answer in markdown',\n",
    "    BinaryContent(data=image_data, media_type='image/png'),\n",
    "])\n",
    "\n",
    "print(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4512aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pixels = 1000*1000  #Max resolution for images\n",
    "\n",
    "def resize_image(pil_image):\n",
    "    org_width, org_height = pil_image.size\n",
    "    print(f\"Original size: {org_width}x{org_height} = {org_width*org_height} pixels\")\n",
    "\n",
    "    # Resize image if too large\n",
    "    if org_width * org_height > max_pixels:\n",
    "        scale_factor = (max_pixels / (org_width * org_height)) ** 0.5\n",
    "        new_width = int(org_width * scale_factor)\n",
    "        new_height = int(org_height * scale_factor)\n",
    "        pil_image.thumbnail((new_width, new_height))\n",
    "        print(f\"Resized to: {pil_image.size[0]}x{pil_image.size[1]} = {pil_image.size[0]*pil_image.size[1]} pixels\")\n",
    "    else:\n",
    "        print(\"No resize needed\")\n",
    "    \n",
    "    return pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (assuming already loaded in previous cells)\n",
    "# client should already be initialized from your previous cells\n",
    "\n",
    "def get_llm_answer_from_image(img_path):\n",
    "    \"\"\"\n",
    "    Read an image containing a math question and get the LLM to answer it\n",
    "    \"\"\"\n",
    "    # Load and resize image\n",
    "    pil_image = PIL.Image.open(img_path)\n",
    "    pil_image = resize_image(pil_image)\n",
    "    model = \"gemini-2.0-flash\"\n",
    "\n",
    "\n",
    "    prompt = [\"\"\"You are a math expert. \n",
    "    Look at this image which contains a math question.\n",
    "    Read the question from the image and solve it step by step.\n",
    "    Show your working clearly.\n",
    "    Don't use markdown.\n",
    "    \"\"\", pil_image]\n",
    "    \n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model,\n",
    "            contents=prompt\n",
    "        )\n",
    "        \n",
    "        answer = response.text\n",
    "        \n",
    "        # Track token usage if available\n",
    "        if hasattr(response, 'usage_metadata') and response.usage_metadata:\n",
    "            tokens = response.usage_metadata.total_token_count\n",
    "            return answer, tokens, model\n",
    "        \n",
    "        return answer, 0\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", 0\n",
    "\n",
    "def process_test_images(input_csv, img_folder, output_csv):\n",
    "    \"\"\"\n",
    "    Process test images and generate answers\n",
    "    \n",
    "    Expected CSV columns:\n",
    "    - image_filename: Name of the image file (e.g., \"question1.jpg\")\n",
    "    - ground_truth: The correct answer\n",
    "    - marking_scheme: The marking criteria\n",
    "    \"\"\"\n",
    "    # Read input CSV\n",
    "    print(f\"Reading CSV from {input_csv}...\")\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = ['image_filename', 'ground_truth', 'marking_scheme']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Initialize answer columns\n",
    "    df['llm_answer'] = \"\"\n",
    "    df['tokens_used'] = 0\n",
    "    df['status'] = \"\"\n",
    "    df['model'] = \"\"\n",
    "    \n",
    "    total_tokens = 0\n",
    "    \n",
    "    # Process each image\n",
    "    print(f\"\\nProcessing {len(df)} images...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_filename = row['image_filename']\n",
    "        img_path = os.path.join(img_folder, img_filename)\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"\\nWarning: Image not found: {img_path}\")\n",
    "            df.at[idx, 'llm_answer'] = \"Image not found\"\n",
    "            df.at[idx, 'status'] = \"ERROR\"\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing: {img_filename}\")\n",
    "        \n",
    "        # Get LLM answer\n",
    "        answer, tokens, model = get_llm_answer_from_image(img_path)\n",
    "        \n",
    "        df.at[idx, 'llm_answer'] = answer\n",
    "        df.at[idx, 'tokens_used'] = tokens\n",
    "        df.at[idx, 'status'] = \"SUCCESS\" if not answer.startswith(\"Error\") else \"ERROR\"\n",
    "        df.at[idx, 'model'] = model\n",
    "        \n",
    "        total_tokens += tokens\n",
    "        print(f\"Tokens used: {tokens} | Total so far: {total_tokens}\")\n",
    "    \n",
    "    # Save output CSV\n",
    "    print(f\"\\nSaving results to {output_csv}...\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images processed: {len(df)}\")\n",
    "    print(f\"Successful: {len(df[df['status'] == 'SUCCESS'])}\")\n",
    "    print(f\"Errors: {len(df[df['status'] == 'ERROR'])}\")\n",
    "    print(f\"Total tokens used: {total_tokens}\")\n",
    "    print(f\"Results saved to: {output_csv}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the test\n",
    "input_csv = \"test_questions_mathform5.csv\"      # CSV with: image_filename, ground_truth, marking_scheme\n",
    "img_folder = \"Soalan maths\\\\form 5\"                     # Folder containing the question images\n",
    "output_csv = \"test_results_f5.csv\"        # Output file with answers\n",
    "\n",
    "results_df = process_test_images(input_csv, img_folder, output_csv)\n",
    "\n",
    "# Display first few results\n",
    "print(\"\\nFirst 3 results:\")\n",
    "print(results_df[['image_filename', 'ground_truth', 'llm_answer', 'status']].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables (assuming already loaded in previous cells)\n",
    "# client should already be initialized from your previous cells\n",
    "# or \"gpt-4-vision-preview\" or \"gpt-4o-mini\"\n",
    "def get_openai_answer_from_image(img_path, model):\n",
    "    \"\"\"\n",
    "    Read an image containing a math question and get OpenAI to answer it\n",
    "    \"\"\"\n",
    "    import base64\n",
    "    \n",
    "    # Load and resize image\n",
    "    pil_image = PIL.Image.open(img_path)\n",
    "    pil_image = resize_image(pil_image)\n",
    "    \n",
    "    # Convert to base64\n",
    "    import io\n",
    "    buffered = io.BytesIO()\n",
    "    pil_image.save(buffered, format=\"PNG\")\n",
    "    base64_image = base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "    \n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": \"\"\"You are a math expert. \n",
    "Look at this image which contains a math question.\n",
    "Read the question from the image and solve it step by step.\n",
    "Show your working clearly.\n",
    "Don't use markdown.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,  # or \"gpt-4-vision-preview\" or \"gpt-4o-mini\"\n",
    "            messages=messages\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        tokens = response.usage.total_tokens\n",
    "        \n",
    "        return answer, tokens, model\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\", 0\n",
    "\n",
    "def process_test_images(input_csv, img_folder, output_csv, model):\n",
    "    \"\"\"\n",
    "    Process test images and generate answers\n",
    "    \n",
    "    Expected CSV columns:\n",
    "    - image_filename: Name of the image file (e.g., \"question1.jpg\")\n",
    "    - ground_truth: The correct answer\n",
    "    - marking_scheme: The marking criteria\n",
    "    \"\"\"\n",
    "    # Read input CSV\n",
    "    print(f\"Reading CSV from {input_csv}...\")\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_cols = ['image_filename', 'ground_truth', 'marking_scheme']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    # Initialize answer columns\n",
    "    df['llm_answer'] = \"\"\n",
    "    df['tokens_used'] = 0\n",
    "    df['status'] = \"\"\n",
    "    df['model'] = \"\"\n",
    "    \n",
    "    total_tokens = 0\n",
    "    \n",
    "    # Process each image\n",
    "    print(f\"\\nProcessing {len(df)} images...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        img_filename = row['image_filename']\n",
    "        img_path = os.path.join(img_folder, img_filename)\n",
    "        \n",
    "        # Check if image exists\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"\\nWarning: Image not found: {img_path}\")\n",
    "            df.at[idx, 'llm_answer'] = \"Image not found\"\n",
    "            df.at[idx, 'status'] = \"ERROR\"\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nProcessing: {img_filename}\")\n",
    "        \n",
    "        # Get LLM answer\n",
    "        answer, tokens, model = get_openai_answer_from_image(img_path, model)\n",
    "        \n",
    "        df.at[idx, 'llm_answer'] = answer\n",
    "        df.at[idx, 'tokens_used'] = tokens\n",
    "        df.at[idx, 'status'] = \"SUCCESS\" if not answer.startswith(\"Error\") else \"ERROR\"\n",
    "        df.at[idx, 'model'] = model\n",
    "        \n",
    "        total_tokens += tokens\n",
    "        print(f\"Tokens used: {tokens} | Total so far: {total_tokens}\")\n",
    "    \n",
    "    # Save output CSV\n",
    "    print(f\"\\nSaving results to {output_csv}...\")\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TEST SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total images processed: {len(df)}\")\n",
    "    print(f\"Successful: {len(df[df['status'] == 'SUCCESS'])}\")\n",
    "    print(f\"Errors: {len(df[df['status'] == 'ERROR'])}\")\n",
    "    print(f\"Total tokens used: {total_tokens}\")\n",
    "    print(f\"Results saved to: {output_csv}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the test\n",
    "input_csv = \"test_questions_mathform5.csv\"      # CSV with: image_filename, ground_truth, marking_scheme\n",
    "img_folder = \"Soalan maths\\\\form 5\"                     # Folder containing the question images\n",
    "output_csv = \"test_results_f5_gpt5mini.csv\"        # Output file with answers\n",
    "model=\"gpt-5-mini\"\n",
    "\n",
    "results_df = process_test_images(input_csv, img_folder, output_csv, model)\n",
    "\n",
    "# Display first few results\n",
    "print(\"\\nFirst 3 results:\")\n",
    "print(results_df[['image_filename', 'ground_truth', 'llm_answer', 'status']].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
