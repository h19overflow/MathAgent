@startuml ACE Framework Sequence Diagram

title Agentic Context Engineering (ACE) - Complete Workflow

actor User
participant "Test Runner" as Runner
participant "Orchestrator" as Orch
box "ACE Core Pipeline" #LightBlue
    participant "Generator" as Gen
    participant "Reflector" as Ref
    participant "Curator" as Cur
end box
participant "LLM Agent" as LLM
database "Context\n(Bullets)" as Context

note over Runner, Context
    **ACE Framework Goal:**
    Incrementally adapt problem-solving context through
    delta updates (not full rewrites) using structured bullets
end note

== Initialization ==
User -> Runner: Start test (form 4 or 5)
activate Runner
Runner -> Orch: initialize_context()
activate Orch
Orch -> Context: Create initial bullets
note right of Context
    **Initial Bullets:**
    • Identify diagram type first
    • Extract numerical values
    • State explicit goal
    • Show calculation steps
    • Verify answer format

    Each bullet has:
    - id (UUID)
    - content (strategy text)
    - helpful_count (int)
    - harmful_count (int)
    - metadata (dict)
end note
Context --> Orch: Context with 5 seed bullets
Orch --> Runner: Initialized context
deactivate Orch

== For Each Problem (Incremental Adaptation Loop) ==
loop Each math problem in dataset
    Runner -> Orch: run_ace_pipeline(agent, context, query, image, ground_truth)
    activate Orch

    note over Orch
        **Pipeline: Generate → Reflect → Curate**
        Context evolves incrementally with each problem
    end note

    == Stage 1: Generate (Context-Aware Problem Solving) ==
    Orch -> Gen: generate_with_context(agent, context, query, image)
    activate Gen

    Gen -> Context: Get relevant bullets\n(helpful_count > 0 or harmful_count == 0)
    Context --> Gen: List of relevant bullets

    note over Gen
        **Enhanced Prompt Construction:**
        Original query + relevant bullets
        Each bullet tagged with [ID:xxx]
        Agent asked to reference IDs if used
    end note

    Gen -> LLM: Run with enhanced prompt + image
    activate LLM
    note right of LLM
        Prompt includes:
        1. Original math question
        2. Available strategies [ID:xxx]
        3. Instruction to reference IDs
        4. Solve step-by-step
    end note
    LLM --> Gen: Solution text
    deactivate LLM

    Gen -> Gen: Extract bullet feedback
    note right of Gen
        **Automatic Feedback:**
        For each bullet, check if:
        - ID mentioned in solution, OR
        - Key words from content used

        → helpful = True/False
    end note

    Gen --> Orch: ReasoningTrace\n(steps, bullet_refs, feedback)
    deactivate Gen

    == Stage 2: Reflect (Delta Extraction via LLM) ==
    Orch -> Ref: reflect_on_reasoning(agent, trace, ground_truth)
    activate Ref

    note over Ref
        **Two-Phase Reflection:**
        1. Deterministic: Process bullet feedback
        2. LLM-based: Extract novel insights
    end note

    Ref -> Ref: Process feedback → increment lessons
    note right of Ref
        For each bullet feedback:
        - If helpful → Lesson(increment_helpful, +1)
        - If not used → Lesson(increment_harmful, +1)

        **Localized updates, not full rewrite**
    end note

    Ref -> LLM: Analyze solution for NEW patterns
    activate LLM
    note right of LLM
        Reflection Prompt:
        "Extract 0-2 novel reusable strategies
        from this solution.
        Only genuinely new patterns."

        Returns: ReflectionOutput with
        new_insights: List[DeltaBullet]
    end note
    LLM --> Ref: ReflectionOutput\n(0-2 new insights)
    deactivate LLM

    Ref -> Ref: Convert insights to add lessons
    note right of Ref
        For each new insight:
        Lesson(action="add",
               bullet_id=UUID,
               content=insight_text)
    end note

    Ref --> Orch: List[Lesson]\n(delta updates)
    deactivate Ref

    == Stage 3: Curate (Grow-and-Refine) ==
    Orch -> Cur: curate_context(context, lessons, mode="lazy")
    activate Cur

    note over Cur
        **Incremental Delta Application**
        Apply lessons one by one to grow context
    end note

    loop For each lesson
        alt lesson.action == "add"
            Cur -> Context: add_bullet(new_bullet)
            note right of Context
                **Grow:** Append new bullet
                with fresh UUID
            end note
        else lesson.action == "increment_helpful/harmful"
            Cur -> Context: get_bullet_by_id(lesson.bullet_id)
            Context --> Cur: Bullet
            Cur -> Context: Update helpful_count or harmful_count
            note right of Context
                **Refine:** Localized counter update
                No content rewrite
            end note
        end
    end

    note over Cur
        **Refinement Decision:**
        - Lazy: Only if len(bullets) > max_size
        - Eager: After every delta
    end note

    alt Should refine (lazy trigger or eager mode)
        Cur -> Cur: deduplicate_bullets()
        note right of Cur
            **Deduplication:**
            Jaccard similarity on content
            Merge counts if similar (threshold=0.7)
        end note

        Cur -> Cur: remove_harmful_bullets()
        note right of Cur
            **Filter:**
            Remove bullets with
            score < 0.3 threshold
        end note

        Cur -> Cur: prune_bullets(max_size=20)
        note right of Cur
            **Prune:**
            Keep top-k by score
            score = helpful / (helpful + harmful)
        end note
    end

    Cur --> Orch: Updated Context
    deactivate Cur

    Orch --> Runner: (answer, updated_context)
    deactivate Orch

    note over Runner
        **Context Persists:**
        Updated context used for next problem
        → Multi-epoch incremental adaptation
    end note

    Runner -> Runner: Save answer to CSV
    Runner -> Context: Context now has evolved bullets\n(updated counts, new strategies)
end

== Finalization ==
Runner -> Runner: Save all results to CSV
Runner -> User: Test complete\n(Final context with learned strategies)
deactivate Runner

note over User, Context
    **Key ACE Properties Achieved:**
    1. ✓ Incremental delta updates (not full rewrites)
    2. ✓ Structured itemized bullets with metadata
    3. ✓ Grow-and-refine with lazy/eager modes
    4. ✓ Localized updates (only affected bullets change)
    5. ✓ Multi-epoch adaptation (context evolves per problem)
    6. ✓ LLM-based reflection for insight extraction
    7. ✓ Deterministic merging (Curator logic is non-LLM)
end note

@enduml
